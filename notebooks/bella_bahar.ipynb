{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62c79104-2ce9-4ce3-a975-2f08ee834ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in intro_video_audio.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in trimmed_audio_bella.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Building video muted_video_bella.mp4.\n",
      "Moviepy - Writing video muted_video_bella.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready muted_video_bella.mp4\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# Load the video clip\n",
    "video_path = \"intro.mp4\"\n",
    "video_clip = VideoFileClip(video_path)\n",
    "\n",
    "# Save the video's audio as an audio file\n",
    "video_audio = video_clip.audio\n",
    "audio_path = \"intro_video_audio.mp3\"\n",
    "video_audio.write_audiofile(audio_path)\n",
    "\n",
    "\n",
    "# Trim the video from 3 to 4 seconds\n",
    "start_time = 5.3  # in seconds\n",
    "end_time = 5.8    # in seconds\n",
    "trimmed_video = video_clip.subclip(start_time, end_time)\n",
    "\n",
    "# Save the audio of the trimmed video\n",
    "audio_path = \"trimmed_audio_bella.mp3\"\n",
    "trimmed_audio = trimmed_video.audio\n",
    "trimmed_audio.write_audiofile(audio_path)\n",
    "\n",
    "# Create a muted version of the trimmed video\n",
    "muted_video_path = \"muted_video_bella.mp4\"\n",
    "muted_video = trimmed_video.set_audio(None)\n",
    "muted_video.write_videofile(muted_video_path, codec=\"libx264\", audio_codec=\"aac\")\n",
    "\n",
    "# Close the video clips\n",
    "video_clip.close()\n",
    "trimmed_video.close()\n",
    "muted_video.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "481124d1-901b-446a-b313-4f3326738c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Duration: 0.5 seconds\n"
     ]
    }
   ],
   "source": [
    "# Get the length of muted video : \n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# Load the video file\n",
    "video_path = \"muted_video_bella.mp4\"  # Replace with your video file path\n",
    "video = VideoFileClip(video_path)\n",
    "\n",
    "# Get the duration of the video in seconds\n",
    "video_duration = video.duration\n",
    "\n",
    "print(\"Video Duration:\", video_duration, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a704ee-1274-462d-b2c8-57632ca5cf94",
   "metadata": {},
   "source": [
    "### Here We trimmed video and audio file where the name \"Bella\" is spoken. And also saved the audio file for the voice clonnig. Now we will do the voice clonnig with new word \"Bahar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02f8fd43-c9a8-4aad-89c2-2e57de352cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No API token found for üê∏Coqui Studio voices - https://coqui.ai \n",
      "Visit üîóhttps://app.coqui.ai/account to get one.\n",
      "Set it as an environment variable `export COQUI_STUDIO_TOKEN=<token>`\n",
      "\n",
      " > Downloading model to /home/fx/.local/share/tts/tts_models--en--ljspeech--tacotron2-DDC_ph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 315M/315M [00:47<00:00, 6.65MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Model's license - apache 2.0\n",
      " > Check https://choosealicense.com/licenses/apache-2.0/ for more info.\n",
      " > Downloading model to /home/fx/.local/share/tts/vocoder_models--en--ljspeech--univnet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 623M/623M [02:02<00:00, 5.10MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Model's license - apache 2.0\n",
      " > Check https://choosealicense.com/licenses/apache-2.0/ for more info.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:7600.0\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:/home/fx/.local/share/tts/tts_models--en--ljspeech--tacotron2-DDC_ph/scale_stats.npy\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 2\n",
      " > Vocoder Model: univnet\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:7600.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:/home/fx/.local/share/tts/vocoder_models--en--ljspeech--univnet/scale_stats.npy\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: univnet_generator\n",
      " > Discriminator Model: univnet_discriminator\n"
     ]
    }
   ],
   "source": [
    "from TTS.api import TTS\n",
    "\n",
    "# Running a multi-speaker and multi-lingual model\n",
    "\n",
    "# List available üê∏TTS models and choose the first one\n",
    "model_name = TTS()\n",
    "model=model_name.list_models()[9]\n",
    "\n",
    "# Init TTS\n",
    "tts = TTS(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1bff9653-9de6-462c-b10c-41f08272aeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['Bahar']\n",
      " > Processing time: 0.17177248001098633\n",
      " > Real-time factor: 0.15563704734723244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bahar_voice_file.wav'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tts.tts_to_file(\"Bahar\", speaker_wav=\"intro_video_audio.wav\",file_path=\"bahar_voice_file.wav\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41f53f8-6187-4c46-aaec-14a41808c870",
   "metadata": {},
   "source": [
    "### Now we will adjust the audio file duration accroding to our muted clip length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ba326e52-052e-4a40-ba8c-9bd6bae230bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before  1.104\n",
      "after 0.529\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "# Load the audio file\n",
    "audio_path = \"bahar_voice_file.wav\"  # Replace with your audio file path\n",
    "audio = AudioSegment.from_wav(audio_path)\n",
    "\n",
    "print(\"before \",len(audio)/1000)\n",
    "# Calculate the new duration (0.5 seconds)\n",
    "new_duration = video_duration*1000  # Duration in milliseconds\n",
    "\n",
    "# Speed up the audio\n",
    "sped_up_audio = audio.speedup(playback_speed= len(audio) / new_duration)\n",
    "\n",
    "# Export the sped-up audio\n",
    "output_path = \"bahar_voice_file.wav\"  # Replace with your desired output path\n",
    "sped_up_audio.export(output_path, format=\"wav\")\n",
    "\n",
    "audio_path = \"bahar_voice_file.wav\"  # Replace with your audio file path\n",
    "audio = AudioSegment.from_wav(audio_path)\n",
    "print(\"after\" ,len(audio)/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca8f8c0-4c0a-4620-b645-aaeaf5a53b0c",
   "metadata": {},
   "source": [
    "### Now we have audio file named   \"bahar_voice_file\"   and video file named   \"muted_video_bella\".   So our next goal is to embed these files with lip syncing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea164e3e-d91d-4e82-9e65-f1983c8fcbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to liop synce and embed.\n",
    "# Did that using wav2lip."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca17a3f-0ab7-4140-895c-b6965261e822",
   "metadata": {},
   "source": [
    "### Now we will replace lip sybnced file into original one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "be83f483-696e-4d07-ae9b-0467cf1e524b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video final_video.mp4.\n",
      "MoviePy - Writing audio in final_videoTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video final_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready final_video.mp4\n"
     ]
    }
   ],
   "source": [
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "from moviepy.editor import *\n",
    "# Load the video clip\n",
    "video_clip = VideoFileClip(\"intro.mp4\")\n",
    "lip_sync_bahar =  VideoFileClip(\"bahar_lip_sync.mp4\")\n",
    "\n",
    "trimmed_clip1 = video_clip.subclip(0, 5.3)\n",
    "trimmed_clip2 = video_clip.subclip(5.8)\n",
    "\n",
    "final_clip=concatenate_videoclips([trimmed_clip1,lip_sync_bahar,trimmed_clip2])\n",
    "final_clip.write_videofile(\"final_video.mp4\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
